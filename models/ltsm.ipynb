{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NOTES\n",
    "Right now only takes close price. Update to include all data in the sequence.\n",
    "\n",
    "After 3 epochs it's loss is basically non-existant. Use an early stop\n",
    "\n",
    "Learn how to use GPU \n",
    "\n",
    "drop_last=True seems necessary for the data loader. The batch_size argument is expecting batches to be that size. But if the whole dataset can't be divided by the batch_size then you had some values remaining that don't fit. Could set batch_size to be some multiple if possible to minimize dropped samples "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24c3094fd6965f05"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchmetrics"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:40:57.678216400Z",
     "start_time": "2024-07-21T01:40:57.666708700Z"
    }
   },
   "id": "initial_id",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DATA_PATH = r'C:\\Users\\connor\\PycharmProjects\\trading\\data\\analytics\\analytics_voo.csv'\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:02.768712600Z",
     "start_time": "2024-07-21T01:40:57.681217200Z"
    }
   },
   "id": "fe54a882ded20973",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'join_date', 'Id',\n       'Date', 'DateLongDescription', 'DateShortDescription', 'DayLongName',\n       'DayShortName', 'MonthLongName', 'MonthShortName', 'CalendarDay',\n       'CalendarWeek', 'CalendarWeekStartDateId', 'CalendarWeekEndDateId',\n       'CalendarDayInWeek', 'CalendarMonth', 'CalendarMonthStartDateId',\n       'CalendarMonthEndDateId', 'CalendarNumberOfDaysInMonth',\n       'CalendarDayInMonth', 'CalendarQuarter', 'CalendarQuarterStartDateId',\n       'CalendarQuarterEndDateId', 'CalendarQuarterStartDate',\n       'CalendarNumberOfDaysInQuarter', 'CalendarDayInQuarter', 'CalendarYear',\n       'CalendarYearEndDateId', 'CalendarYearStartDate',\n       'CalendarNumberOfDaysInYear', 'month_join_key', 'year_join_key',\n       'seven_day_ema', 'CPALTT01USM657N', 'DFF', 'EXPINF10YR', 'GDPC1',\n       'RSXFS', 'T10YFF', 'UNRATE', 'macd', 'macd_signal', 'macd_hist',\n       'daily_obv', 'target'],\n      dtype='object')"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:02.787269700Z",
     "start_time": "2024-07-21T01:41:02.768712600Z"
    }
   },
   "id": "84e113a86696fd67",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "non_target_columns = ['open', 'high', 'low', 'volume', 'CPALTT01USM657N', 'DFF', 'EXPINF10YR', 'GDPC1', 'RSXFS', 'T10YFF', 'UNRATE', 'macd', 'macd_signal', 'macd_hist', 'daily_obv', 'seven_day_ema', 'close']\n",
    "\n",
    "df_cols = df[non_target_columns]\n",
    "\n",
    "# version with just close price and date\n",
    "df_target_train = df[['date', 'close']].where(df.date <= '2020-01-01')\n",
    "df_target_train.dropna(inplace=True)\n",
    "df_target_test = df[['date', 'close']].where(df.date > '2020-01-01')\n",
    "df_target_test.dropna(inplace=True)\n",
    "\n",
    "# version with all columns\n",
    "df_target_train_v2 = df[non_target_columns].where(df.date <= '2020-01-01')\n",
    "df_target_train_v2.dropna(inplace=True)\n",
    "df_target_test_v2 = df[non_target_columns].where(df.date > '2020-01-01')\n",
    "df_target_test_v2.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:03.364607200Z",
     "start_time": "2024-07-21T01:41:02.773269100Z"
    }
   },
   "id": "d1c8b93f981cd0f5",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'close'], dtype='object')\n",
      "\n",
      "Index(['open', 'high', 'low', 'volume', 'CPALTT01USM657N', 'DFF', 'EXPINF10YR',\n",
      "       'GDPC1', 'RSXFS', 'T10YFF', 'UNRATE', 'macd', 'macd_signal',\n",
      "       'macd_hist', 'daily_obv', 'seven_day_ema', 'close'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_target_train.columns)\n",
    "print()\n",
    "print(df_target_train_v2.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:03.371874200Z",
     "start_time": "2024-07-21T01:41:03.364607200Z"
    }
   },
   "id": "4b6c67e1f20487e",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_sequences(df, seq_length, num_rows=len(df), include_all_features=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    df: pandas dataframe with at least 2 columns, a date column and a target column\n",
    "    seq_length: How long the sequence should be. \n",
    "    num_rows: How many rows to use. Will pull all rows unless num_rows is provided, in which case the top num_rows will be pulled.\n",
    "    include_all_features: Whether to use just the target column for the sequence, or to include all features.\n",
    "        \n",
    "    Output:\n",
    "    Generates a sequence of seq_length length. It's shape is [num_rows, seq_length] if include_all_features is False, else [num_rows, seq_length * len(df.columns)]. \n",
    "    A sequence refers to how many should be appended as columns. \n",
    "    For example, if df = [['2020-01-01',100], ['2020-01-02', 101], ['2020-01-03', 102]] and seq_length = 2, the generated sequence will be [[101,102], [102,103]]. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    xs, ys = [], []\n",
    "    if include_all_features == True:\n",
    "        feature_num = len(df.columns)\n",
    "        seq_length = seq_length * feature_num\n",
    "    if include_all_features == False:\n",
    "        for itr in range(num_rows - seq_length):\n",
    "            x = df.iloc[itr:(itr + seq_length), -1]\n",
    "            y = df.iloc[itr + seq_length, -1]\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "    elif include_all_features == True:\n",
    "        for itr in range(num_rows - seq_length):\n",
    "            x = df.iloc[itr:(itr + seq_length), :]\n",
    "            y = df.iloc[itr + seq_length, -1]\n",
    "            # when you get more than 1 column, it'll append an array to the array which makes it 3d instead of 2d. Flatten out sample into single row\n",
    "            x_reshaped = x.to_numpy().reshape(-1, 1)\n",
    "            xs.append(x_reshaped)\n",
    "            ys.append(y)\n",
    "    else:\n",
    "        print(f\"error: include_all_features accepts True or False, got {include_all_features} instead.\")\n",
    "    return np.array(xs), np.array(ys)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:03.371874200Z",
     "start_time": "2024-07-21T01:41:03.368233900Z"
    }
   },
   "id": "7a13bd55cd725fa",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create training set\n",
    "sequence_len = 10\n",
    "num_rows = 10000\n",
    "X_train, y_train = create_sequences(df_target_train, sequence_len, num_rows)\n",
    "X_test, y_test = create_sequences(df_target_test, sequence_len, num_rows)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:04.236700400Z",
     "start_time": "2024-07-21T01:41:03.371874200Z"
    }
   },
   "id": "246d1ed0ddd399a4",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create training set\n",
    "X_train_v2, y_train_v2 = create_sequences(df_target_train_v2, sequence_len, num_rows, include_all_features=True)\n",
    "X_test_v2, y_test_v2 = create_sequences(df_target_test_v2, sequence_len, num_rows, include_all_features=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:04.930950700Z",
     "start_time": "2024-07-21T01:41:04.237702400Z"
    }
   },
   "id": "f7c131fb11dac19c",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "# using all fields available"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c459d4662a2e0b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9915, 1445]) torch.Size([9915])\n",
      "input sample: tensor([ 8.3935e+01,  8.4042e+01,  8.3820e+01,  ..., -1.6520e+05,\n",
      "         8.1712e+01,  8.3516e+01])\n",
      "label sample: tensor(83.4850)\n"
     ]
    }
   ],
   "source": [
    "# convert df into objects Torch can read\n",
    "torch_X_train  = torch.from_numpy(X_train_v2.reshape(X_train_v2.shape[0], X_train_v2.shape[1])).float()\n",
    "torch_y_train = torch.from_numpy(y_train_v2).float()\n",
    "torch_X_test = torch.from_numpy(X_test_v2.reshape(X_test_v2.shape[0], X_test_v2.shape[1])).float()\n",
    "torch_y_test = torch.from_numpy(y_test_v2).float()\n",
    "\n",
    "print(torch_X_train.shape, torch_y_train.shape)\n",
    "# create test and train sets\n",
    "train_data_set = TensorDataset(torch_X_train, torch_y_train)\n",
    "test_data_set = TensorDataset(torch_X_test, torch_y_test)\n",
    "\n",
    "# confirm it works\n",
    "sample = train_data_set[0]\n",
    "input_sample, label_sample = sample\n",
    "print('input sample:', input_sample)\n",
    "print('label sample:', label_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:04.948391600Z",
     "start_time": "2024-07-21T01:41:04.930950700Z"
    }
   },
   "id": "382fadba79bfaaee",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Using just the close price"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:04.959399600Z",
     "start_time": "2024-07-21T01:41:04.949328Z"
    }
   },
   "id": "ec4d4cde0b78850f",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # convert df into objects Torch can read\n",
    "# torch_X_train  = torch.from_numpy(X_train).float()\n",
    "# torch_y_train = torch.from_numpy(y_train).float()\n",
    "# torch_X_test = torch.from_numpy(X_test).float()\n",
    "# torch_y_test = torch.from_numpy(y_test).float()\n",
    "# \n",
    "# # create test and train sets\n",
    "# train_data_set = TensorDataset(torch_X_train, torch_y_train)\n",
    "# test_data_set = TensorDataset(torch_X_test, torch_y_test)\n",
    "# \n",
    "# # confirm it works\n",
    "# sample = train_data_set[0]\n",
    "# input_sample, label_sample = sample\n",
    "# print('input sample:', input_sample)\n",
    "# print('label sample:', label_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:04.959399600Z",
     "start_time": "2024-07-21T01:41:04.952377400Z"
    }
   },
   "id": "8d2b0b4d1930876e",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1445])\n"
     ]
    }
   ],
   "source": [
    "print(input_sample.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:04.959399600Z",
     "start_time": "2024-07-21T01:41:04.953887400Z"
    }
   },
   "id": "7ea83ed54f081155",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "shuffle = True\n",
    "hidden_size = 5\n",
    "num_layers = 2\n",
    "\n",
    "# create dataloader\n",
    "train_dataloader = DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n",
    "test_dataloader = DataLoader(test_data_set, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n",
    "# test loader\n",
    "# x, y = next(iter(train_dataloader))\n",
    "# \n",
    "# print('x', x, 'y', y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:04.984482800Z",
     "start_time": "2024-07-21T01:41:04.957713300Z"
    }
   },
   "id": "e992d7c8e1e29632",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# LTSM\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__() #super makes all the methods available in nn.Module available for the new class Net\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "        c0 = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:41:04.985479Z",
     "start_time": "2024-07-21T01:41:04.959399600Z"
    }
   },
   "id": "d6d6aae47a1a113e",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6739.86572265625\n",
      "Epoch 2, Loss: 5653.71337890625\n",
      "Epoch 3, Loss: 5081.59716796875\n",
      "Epoch 4, Loss: 4532.958984375\n",
      "Epoch 5, Loss: 3710.39697265625\n",
      "Epoch 6, Loss: 3180.00439453125\n",
      "Epoch 7, Loss: 2479.31103515625\n",
      "Epoch 8, Loss: 2045.7144775390625\n",
      "Epoch 9, Loss: 1534.8338623046875\n",
      "Epoch 10, Loss: 1133.159912109375\n",
      "Epoch 11, Loss: 795.7372436523438\n",
      "Epoch 12, Loss: 574.6461791992188\n",
      "Epoch 13, Loss: 392.6899108886719\n",
      "Epoch 14, Loss: 240.85903930664062\n",
      "Epoch 15, Loss: 138.28704833984375\n",
      "Epoch 16, Loss: 73.03668975830078\n",
      "Epoch 17, Loss: 18.597078323364258\n",
      "Epoch 18, Loss: 11.70531940460205\n",
      "Epoch 19, Loss: 11.268365859985352\n",
      "Epoch 20, Loss: 6.2229719161987305\n",
      "Epoch 21, Loss: 6.2082366943359375\n",
      "Epoch 22, Loss: 5.539273262023926\n",
      "Epoch 23, Loss: 3.9265456199645996\n",
      "Epoch 24, Loss: 3.910283327102661\n",
      "Epoch 25, Loss: 7.9704389572143555\n",
      "Epoch 26, Loss: 5.355321407318115\n",
      "Epoch 27, Loss: 7.322512149810791\n",
      "Epoch 28, Loss: 6.673825263977051\n",
      "Epoch 29, Loss: 2.541616201400757\n",
      "Epoch 30, Loss: 4.295714378356934\n",
      "Epoch 31, Loss: 7.133352756500244\n",
      "Epoch 32, Loss: 6.656015872955322\n",
      "Epoch 33, Loss: 5.365059852600098\n",
      "Epoch 34, Loss: 1.2458871603012085\n",
      "Epoch 35, Loss: 3.6874706745147705\n",
      "Epoch 36, Loss: 4.889216423034668\n",
      "Epoch 37, Loss: 3.813025712966919\n",
      "Epoch 38, Loss: 3.3649585247039795\n",
      "Epoch 39, Loss: 1.3078083992004395\n",
      "Epoch 40, Loss: 0.7686000466346741\n",
      "Epoch 41, Loss: 0.13926748931407928\n",
      "Epoch 42, Loss: 0.7274964451789856\n",
      "Epoch 43, Loss: 0.1908038854598999\n",
      "Epoch 44, Loss: 0.29482579231262207\n",
      "Epoch 45, Loss: 0.47496724128723145\n",
      "Epoch 46, Loss: 0.36890408396720886\n",
      "Epoch 47, Loss: 0.06397485733032227\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "num_features = 1 # this right now is just the close date. \n",
    "\n",
    "net = Net(input_size=num_features)\n",
    "#criterion = nn.BCELoss(reduction='sum') #you'll need to use the binary close price higher for this\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    net.parameters(), lr=learning_rate\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for seqs, labels in train_dataloader:\n",
    "        seqs = seqs.view(batch_size, torch_X_train.shape[1], num_features)\n",
    "        outputs = net(seqs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    # early break if loss isn't changing beyond the learning rate\n",
    "    if loss.item() < .1:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:51:12.823465Z",
     "start_time": "2024-07-21T01:41:04.963479500Z"
    }
   },
   "id": "2790534f5428cde2",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 35426.28125\n",
      "Test RMSE: 188.2187042236328\n"
     ]
    }
   ],
   "source": [
    "# Define MSE metric\n",
    "mse = torchmetrics.regression.MeanSquaredError()\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for seqs, labels in test_dataloader:\n",
    "        seqs = seqs.view(batch_size, torch_X_test.shape[1], num_features)\n",
    "        # Pass seqs to net and squeeze the result\n",
    "        outputs = net(seqs).squeeze()\n",
    "        mse(outputs, labels)\n",
    "\n",
    "# Compute final metric value\n",
    "test_mse = mse.compute()\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "print(f\"Test RMSE: {test_mse**.5}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:51:18.162266300Z",
     "start_time": "2024-07-21T01:51:12.814959600Z"
    }
   },
   "id": "ae6937e7eff7177e",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## used for binary classifcation\n",
    "# f1 = torchmetrics.F1Score(num_classes=2)\n",
    "# \n",
    "# net.eval()\n",
    "# with torch.no_grad():\n",
    "#     for seqs, labels in test_dataloader:\n",
    "#         seqs = seqs.view(batch_size, num_features, 1)\n",
    "#         outputs = net(seqs).squeeze()\n",
    "#         f1.compute()\n",
    "#         \n",
    "# print(f\"Test F1 score: {f1.compute()}\")\n",
    "\n",
    "# acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "# \n",
    "# net.eval()\n",
    "# with torch.no_grad():\n",
    "#     for seqs, labels in test_dataloader:\n",
    "#         seqs = seqs.view(batch_size, sequence_len, num_features)\n",
    "#         outputs = net(seqs).squeeze()\n",
    "#         acc.compute()\n",
    "# \n",
    "# print(f\"Test accuracy score: {acc.compute()}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:51:18.162266300Z",
     "start_time": "2024-07-21T01:51:18.156803900Z"
    }
   },
   "id": "a9824920abf3b48d",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Error when using just the close price:\n",
    "274 RMSE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8f4ef39c0db66fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Error when using all fields\n",
    "277 RMSE\n",
    "\n",
    "when using 10000 samples: 188"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "769469f6c81222bd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T01:51:18.163266Z",
     "start_time": "2024-07-21T01:51:18.158759500Z"
    }
   },
   "id": "8d28dd77fdd0b594",
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
