{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NOTES\n",
    "Right now only takes close price. Update to include all data in the sequence.\n",
    "\n",
    "After 3 epochs it's loss is basically non-existant. Use an early stop\n",
    "\n",
    "Learn how to use GPU \n",
    "\n",
    "drop_last=True seems necessary for the data loader. The batch_size argument is expecting batches to be that size. But if the whole dataset can't be divided by the batch_size then you had some values remaining that don't fit. Could set batch_size to be some multiple if possible to minimize dropped samples "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24c3094fd6965f05"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchmetrics"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:29.104922100Z",
     "start_time": "2024-07-21T15:37:29.089897700Z"
    }
   },
   "id": "initial_id",
   "execution_count": 386
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DATA_PATH = r'C:\\Users\\connor\\PycharmProjects\\trading\\data\\analytics\\analytics_voo.csv'\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:34.216493200Z",
     "start_time": "2024-07-21T15:37:29.106920800Z"
    }
   },
   "id": "fe54a882ded20973",
   "execution_count": 387
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'join_date', 'Id',\n       'Date', 'DateLongDescription', 'DateShortDescription', 'DayLongName',\n       'DayShortName', 'MonthLongName', 'MonthShortName', 'CalendarDay',\n       'CalendarWeek', 'CalendarWeekStartDateId', 'CalendarWeekEndDateId',\n       'CalendarDayInWeek', 'CalendarMonth', 'CalendarMonthStartDateId',\n       'CalendarMonthEndDateId', 'CalendarNumberOfDaysInMonth',\n       'CalendarDayInMonth', 'CalendarQuarter', 'CalendarQuarterStartDateId',\n       'CalendarQuarterEndDateId', 'CalendarQuarterStartDate',\n       'CalendarNumberOfDaysInQuarter', 'CalendarDayInQuarter', 'CalendarYear',\n       'CalendarYearEndDateId', 'CalendarYearStartDate',\n       'CalendarNumberOfDaysInYear', 'month_join_key', 'year_join_key',\n       'seven_day_ema', 'CPALTT01USM657N', 'DFF', 'EXPINF10YR', 'GDPC1',\n       'RSXFS', 'T10YFF', 'UNRATE', 'macd', 'macd_signal', 'macd_hist',\n       'daily_obv', 'target'],\n      dtype='object')"
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:34.225252Z",
     "start_time": "2024-07-21T15:37:34.217492600Z"
    }
   },
   "id": "84e113a86696fd67",
   "execution_count": 388
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "non_target_columns = ['open', 'high', 'low', 'close', 'volume', 'CPALTT01USM657N', 'DFF', 'EXPINF10YR', 'GDPC1', 'RSXFS', 'T10YFF', 'UNRATE', 'macd', 'macd_signal', 'macd_hist', 'daily_obv', 'seven_day_ema', 'close', 'target']\n",
    "\n",
    "df_cols = df[non_target_columns]\n",
    "\n",
    "# version with just close price and date\n",
    "df_target_train = df[['date', 'target']].where(df.date <= '2020-01-01')\n",
    "df_target_train.dropna(inplace=True)\n",
    "df_target_test = df[['date', 'target']].where(df.date > '2020-01-01')\n",
    "df_target_test.dropna(inplace=True)\n",
    "\n",
    "# version with all columns\n",
    "df_target_train_v2 = df[non_target_columns].where(df.date <= '2020-01-01')\n",
    "df_target_train_v2.dropna(inplace=True)\n",
    "df_target_test_v2 = df[non_target_columns].where(df.date > '2020-01-01')\n",
    "df_target_test_v2.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:34.964161500Z",
     "start_time": "2024-07-21T15:37:34.220251400Z"
    }
   },
   "id": "d1c8b93f981cd0f5",
   "execution_count": 389
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'target'], dtype='object')\n",
      "\n",
      "Index(['open', 'high', 'low', 'close', 'volume', 'CPALTT01USM657N', 'DFF',\n",
      "       'EXPINF10YR', 'GDPC1', 'RSXFS', 'T10YFF', 'UNRATE', 'macd',\n",
      "       'macd_signal', 'macd_hist', 'daily_obv', 'seven_day_ema', 'close',\n",
      "       'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_target_train.columns)\n",
    "print()\n",
    "print(df_target_train_v2.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:34.974156600Z",
     "start_time": "2024-07-21T15:37:34.965162500Z"
    }
   },
   "id": "4b6c67e1f20487e",
   "execution_count": 390
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_sequences(df, seq_length, num_rows=len(df), include_all_features=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    df: pandas dataframe with at least 2 columns, a date column and a target column\n",
    "    seq_length: How long the sequence should be. \n",
    "    num_rows: How many rows to use. Will pull all rows unless num_rows is provided, in which case the top num_rows will be pulled.\n",
    "    include_all_features: Whether to use just the target column for the sequence, or to include all features.\n",
    "        \n",
    "    Output:\n",
    "    Generates a sequence of seq_length length. It's shape is [num_rows, seq_length] if include_all_features is False, else [num_rows, seq_length * len(df.columns)]. \n",
    "    A sequence refers to how many should be appended as columns. \n",
    "    For example, if df = [['2020-01-01',100], ['2020-01-02', 101], ['2020-01-03', 102]] and seq_length = 2, the generated sequence will be [[101,102], [102,103]]. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    xs, ys = [], []\n",
    "    \n",
    "    if include_all_features == False:\n",
    "        for itr in range(num_rows - seq_length):\n",
    "            x = df.iloc[itr:(itr + seq_length), -1]\n",
    "            y = df.iloc[itr + seq_length, -1]\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "    elif include_all_features == True:\n",
    "        for itr in range(num_rows - seq_length):\n",
    "            x = df.iloc[itr:(itr + seq_length), :]\n",
    "            y = df.iloc[itr + seq_length, -1]\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "    else:\n",
    "        print(f\"error: include_all_features accepts True or False, got {include_all_features} instead.\")\n",
    "    return np.array(xs), np.array(ys)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:34.974156600Z",
     "start_time": "2024-07-21T15:37:34.967610800Z"
    }
   },
   "id": "7a13bd55cd725fa",
   "execution_count": 391
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create training set\n",
    "sequence_len = 10\n",
    "num_rows = 100000\n",
    "X_train, y_train = create_sequences(df_target_train, sequence_len, num_rows)\n",
    "X_test, y_test = create_sequences(df_target_test, sequence_len, num_rows)\n",
    "\n",
    "X_train_v2, y_train_v2 = create_sequences(df_target_train_v2, sequence_len, num_rows, include_all_features=True)\n",
    "X_test_v2, y_test_v2 = create_sequences(df_target_test_v2, sequence_len, num_rows, include_all_features=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:57.905164700Z",
     "start_time": "2024-07-21T15:37:34.971155500Z"
    }
   },
   "id": "246d1ed0ddd399a4",
   "execution_count": 392
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      open    high     low   close  volume  CPALTT01USM657N   DFF  EXPINF10YR  \\\n0   83.935  84.042  83.820  83.967     232          0.12452  0.19    1.574237   \n1   83.888  83.995  83.743  83.889     150          0.12452  0.19    1.574237   \n2   83.888  83.995  83.774  83.920    1600          0.12452  0.19    1.574237   \n3   83.904  84.011  83.776  83.923     100          0.12452  0.19    1.574237   \n4   83.966  84.073  83.851  83.998     698          0.12452  0.19    1.574237   \n..     ...     ...     ...     ...     ...              ...   ...         ...   \n95  83.577  83.684  83.463  83.609      50          0.12452  0.19    1.574237   \n96  83.608  83.715  83.494  83.640      93          0.12452  0.19    1.574237   \n97  83.593  83.700  83.479  83.625     100          0.12452  0.19    1.574237   \n98  83.733  83.840  83.618  83.765     100          0.12452  0.19    1.574237   \n99  83.779  83.886  83.665  83.811     103          0.12452  0.19    1.574237   \n\n        GDPC1     RSXFS  T10YFF  UNRATE    macd  macd_signal  macd_hist  \\\n0   16960.864  323990.0    2.48     9.4  1.1427       1.1947    -0.0521   \n1   16960.864  323990.0    2.48     9.4  1.1427       1.1947    -0.0521   \n2   16960.864  323990.0    2.48     9.4  1.1427       1.1947    -0.0521   \n3   16960.864  323990.0    2.48     9.4  1.1427       1.1947    -0.0521   \n4   16960.864  323990.0    2.48     9.4  1.1427       1.1947    -0.0521   \n..        ...       ...     ...     ...     ...          ...        ...   \n95  16960.864  323990.0    2.56     9.4  1.1110       1.1834    -0.0724   \n96  16960.864  323990.0    2.56     9.4  1.1110       1.1834    -0.0724   \n97  16960.864  323990.0    2.56     9.4  1.1110       1.1834    -0.0724   \n98  16960.864  323990.0    2.56     9.4  1.1110       1.1834    -0.0724   \n99  16960.864  323990.0    2.56     9.4  1.1110       1.1834    -0.0724   \n\n    daily_obv  seven_day_ema   close  target  \n0   -148100.0        81.6086  83.967       0  \n1   -148100.0        81.6086  83.889       1  \n2   -148100.0        81.6086  83.920       1  \n3   -148100.0        81.6086  83.923       1  \n4   -148100.0        81.6086  83.998       1  \n..        ...            ...     ...     ...  \n95  -165200.0        81.7122  83.609       1  \n96  -165200.0        81.7122  83.640       0  \n97  -165200.0        81.7122  83.625       1  \n98  -165200.0        81.7122  83.765       1  \n99  -165200.0        81.7122  83.811       1  \n\n[100 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>CPALTT01USM657N</th>\n      <th>DFF</th>\n      <th>EXPINF10YR</th>\n      <th>GDPC1</th>\n      <th>RSXFS</th>\n      <th>T10YFF</th>\n      <th>UNRATE</th>\n      <th>macd</th>\n      <th>macd_signal</th>\n      <th>macd_hist</th>\n      <th>daily_obv</th>\n      <th>seven_day_ema</th>\n      <th>close</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>83.935</td>\n      <td>84.042</td>\n      <td>83.820</td>\n      <td>83.967</td>\n      <td>232</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.48</td>\n      <td>9.4</td>\n      <td>1.1427</td>\n      <td>1.1947</td>\n      <td>-0.0521</td>\n      <td>-148100.0</td>\n      <td>81.6086</td>\n      <td>83.967</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>83.888</td>\n      <td>83.995</td>\n      <td>83.743</td>\n      <td>83.889</td>\n      <td>150</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.48</td>\n      <td>9.4</td>\n      <td>1.1427</td>\n      <td>1.1947</td>\n      <td>-0.0521</td>\n      <td>-148100.0</td>\n      <td>81.6086</td>\n      <td>83.889</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>83.888</td>\n      <td>83.995</td>\n      <td>83.774</td>\n      <td>83.920</td>\n      <td>1600</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.48</td>\n      <td>9.4</td>\n      <td>1.1427</td>\n      <td>1.1947</td>\n      <td>-0.0521</td>\n      <td>-148100.0</td>\n      <td>81.6086</td>\n      <td>83.920</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>83.904</td>\n      <td>84.011</td>\n      <td>83.776</td>\n      <td>83.923</td>\n      <td>100</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.48</td>\n      <td>9.4</td>\n      <td>1.1427</td>\n      <td>1.1947</td>\n      <td>-0.0521</td>\n      <td>-148100.0</td>\n      <td>81.6086</td>\n      <td>83.923</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>83.966</td>\n      <td>84.073</td>\n      <td>83.851</td>\n      <td>83.998</td>\n      <td>698</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.48</td>\n      <td>9.4</td>\n      <td>1.1427</td>\n      <td>1.1947</td>\n      <td>-0.0521</td>\n      <td>-148100.0</td>\n      <td>81.6086</td>\n      <td>83.998</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>83.577</td>\n      <td>83.684</td>\n      <td>83.463</td>\n      <td>83.609</td>\n      <td>50</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.56</td>\n      <td>9.4</td>\n      <td>1.1110</td>\n      <td>1.1834</td>\n      <td>-0.0724</td>\n      <td>-165200.0</td>\n      <td>81.7122</td>\n      <td>83.609</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>83.608</td>\n      <td>83.715</td>\n      <td>83.494</td>\n      <td>83.640</td>\n      <td>93</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.56</td>\n      <td>9.4</td>\n      <td>1.1110</td>\n      <td>1.1834</td>\n      <td>-0.0724</td>\n      <td>-165200.0</td>\n      <td>81.7122</td>\n      <td>83.640</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>83.593</td>\n      <td>83.700</td>\n      <td>83.479</td>\n      <td>83.625</td>\n      <td>100</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.56</td>\n      <td>9.4</td>\n      <td>1.1110</td>\n      <td>1.1834</td>\n      <td>-0.0724</td>\n      <td>-165200.0</td>\n      <td>81.7122</td>\n      <td>83.625</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>83.733</td>\n      <td>83.840</td>\n      <td>83.618</td>\n      <td>83.765</td>\n      <td>100</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.56</td>\n      <td>9.4</td>\n      <td>1.1110</td>\n      <td>1.1834</td>\n      <td>-0.0724</td>\n      <td>-165200.0</td>\n      <td>81.7122</td>\n      <td>83.765</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>83.779</td>\n      <td>83.886</td>\n      <td>83.665</td>\n      <td>83.811</td>\n      <td>103</td>\n      <td>0.12452</td>\n      <td>0.19</td>\n      <td>1.574237</td>\n      <td>16960.864</td>\n      <td>323990.0</td>\n      <td>2.56</td>\n      <td>9.4</td>\n      <td>1.1110</td>\n      <td>1.1834</td>\n      <td>-0.0724</td>\n      <td>-165200.0</td>\n      <td>81.7122</td>\n      <td>83.811</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 19 columns</p>\n</div>"
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[non_target_columns].head(n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:57.953340400Z",
     "start_time": "2024-07-21T15:37:57.906165400Z"
    }
   },
   "id": "74cd4beed5c9b6cf",
   "execution_count": 393
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1., 1., 1., 1., 1., 0., 1., 1., 0.])"
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:57.954340500Z",
     "start_time": "2024-07-21T15:37:57.947304400Z"
    }
   },
   "id": "a482e6f28809fe93",
   "execution_count": 394
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:57.954340500Z",
     "start_time": "2024-07-21T15:37:57.950572600Z"
    }
   },
   "id": "ecf5237b9b95ddb6",
   "execution_count": 395
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 8.39350000e+01,  8.40420000e+01,  8.38200000e+01,\n         8.39670000e+01,  2.32000000e+02,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.39670000e+01,\n         0.00000000e+00],\n       [ 8.38880000e+01,  8.39950000e+01,  8.37430000e+01,\n         8.38890000e+01,  1.50000000e+02,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.38890000e+01,\n         1.00000000e+00],\n       [ 8.38880000e+01,  8.39950000e+01,  8.37740000e+01,\n         8.39200000e+01,  1.60000000e+03,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.39200000e+01,\n         1.00000000e+00],\n       [ 8.39040000e+01,  8.40110000e+01,  8.37760000e+01,\n         8.39230000e+01,  1.00000000e+02,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.39230000e+01,\n         1.00000000e+00],\n       [ 8.39660000e+01,  8.40730000e+01,  8.38510000e+01,\n         8.39980000e+01,  6.98000000e+02,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.39980000e+01,\n         1.00000000e+00],\n       [ 8.41680000e+01,  8.42760000e+01,  8.40530000e+01,\n         8.42000000e+01,  1.00000000e+02,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.42000000e+01,\n         1.00000000e+00],\n       [ 8.42770000e+01,  8.43850000e+01,  8.41620000e+01,\n         8.43090000e+01,  3.50000000e+02,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.43090000e+01,\n         0.00000000e+00],\n       [ 8.41370000e+01,  8.42440000e+01,  8.40220000e+01,\n         8.41690000e+01,  1.00000000e+02,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.41690000e+01,\n         1.00000000e+00],\n       [ 8.41520000e+01,  8.42600000e+01,  8.40370000e+01,\n         8.41840000e+01,  3.00000000e+02,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.41840000e+01,\n         1.00000000e+00],\n       [ 8.42460000e+01,  8.43530000e+01,  8.41310000e+01,\n         8.42780000e+01,  2.35000000e+02,  1.24519889e-01,\n         1.90000000e-01,  1.57423670e+00,  1.69608640e+04,\n         3.23990000e+05,  2.48000000e+00,  9.40000000e+00,\n         1.14270000e+00,  1.19470000e+00, -5.21000000e-02,\n        -1.48100000e+05,  8.16086000e+01,  8.42780000e+01,\n         0.00000000e+00]])"
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_v2[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:57.964213500Z",
     "start_time": "2024-07-21T15:37:57.953340400Z"
    }
   },
   "id": "16ef6c587bfbc278",
   "execution_count": 396
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_v2[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:57.966213300Z",
     "start_time": "2024-07-21T15:37:57.957203800Z"
    }
   },
   "id": "639c00fe086fe9e3",
   "execution_count": 397
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99990 99990\n",
      "99990 99990\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_train_v2))\n",
    "print(len(y_train), len(y_train_v2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:57.966213300Z",
     "start_time": "2024-07-21T15:37:57.959862Z"
    }
   },
   "id": "fd94e73620d73161",
   "execution_count": 398
  },
  {
   "cell_type": "markdown",
   "source": [
    "# using all fields available"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c459d4662a2e0b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([99990, 10, 19]) torch.Size([99990])\n",
      "input sample: tensor([[ 8.3935e+01,  8.4042e+01,  8.3820e+01,  8.3967e+01,  2.3200e+02,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.3967e+01,  0.0000e+00],\n",
      "        [ 8.3888e+01,  8.3995e+01,  8.3743e+01,  8.3889e+01,  1.5000e+02,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.3889e+01,  1.0000e+00],\n",
      "        [ 8.3888e+01,  8.3995e+01,  8.3774e+01,  8.3920e+01,  1.6000e+03,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.3920e+01,  1.0000e+00],\n",
      "        [ 8.3904e+01,  8.4011e+01,  8.3776e+01,  8.3923e+01,  1.0000e+02,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.3923e+01,  1.0000e+00],\n",
      "        [ 8.3966e+01,  8.4073e+01,  8.3851e+01,  8.3998e+01,  6.9800e+02,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.3998e+01,  1.0000e+00],\n",
      "        [ 8.4168e+01,  8.4276e+01,  8.4053e+01,  8.4200e+01,  1.0000e+02,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.4200e+01,  1.0000e+00],\n",
      "        [ 8.4277e+01,  8.4385e+01,  8.4162e+01,  8.4309e+01,  3.5000e+02,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.4309e+01,  0.0000e+00],\n",
      "        [ 8.4137e+01,  8.4244e+01,  8.4022e+01,  8.4169e+01,  1.0000e+02,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.4169e+01,  1.0000e+00],\n",
      "        [ 8.4152e+01,  8.4260e+01,  8.4037e+01,  8.4184e+01,  3.0000e+02,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.4184e+01,  1.0000e+00],\n",
      "        [ 8.4246e+01,  8.4353e+01,  8.4131e+01,  8.4278e+01,  2.3500e+02,\n",
      "          1.2452e-01,  1.9000e-01,  1.5742e+00,  1.6961e+04,  3.2399e+05,\n",
      "          2.4800e+00,  9.4000e+00,  1.1427e+00,  1.1947e+00, -5.2100e-02,\n",
      "         -1.4810e+05,  8.1609e+01,  8.4278e+01,  0.0000e+00]])\n",
      "label sample: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# convert df into objects Torch can read\n",
    "torch_X_train  = torch.from_numpy(X_train_v2).float()\n",
    "torch_y_train = torch.from_numpy(y_train_v2).float()\n",
    "torch_X_test = torch.from_numpy(X_test_v2).float()\n",
    "torch_y_test = torch.from_numpy(y_test_v2).float()\n",
    "\n",
    "print(torch_X_train.shape, torch_y_train.shape)\n",
    "# create test and train sets\n",
    "train_data_set = TensorDataset(torch_X_train, torch_y_train)\n",
    "test_data_set = TensorDataset(torch_X_test, torch_y_test)\n",
    "\n",
    "# confirm it works\n",
    "sample = train_data_set[0]\n",
    "input_sample, label_sample = sample\n",
    "print('input sample:', input_sample)\n",
    "print('label sample:', label_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:58.012313100Z",
     "start_time": "2024-07-21T15:37:57.962213200Z"
    }
   },
   "id": "382fadba79bfaaee",
   "execution_count": 399
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using just the close price"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95a58c3ea66f325d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # convert df into objects Torch can read\n",
    "# torch_X_train  = torch.from_numpy(X_train).float()\n",
    "# torch_y_train = torch.from_numpy(y_train).float()\n",
    "# torch_X_test = torch.from_numpy(X_test).float()\n",
    "# torch_y_test = torch.from_numpy(y_test).float()\n",
    "# \n",
    "# # create test and train sets\n",
    "# train_data_set = TensorDataset(torch_X_train, torch_y_train)\n",
    "# test_data_set = TensorDataset(torch_X_test, torch_y_test)\n",
    "# \n",
    "# # confirm it works\n",
    "# sample = train_data_set[0]\n",
    "# input_sample, label_sample = sample\n",
    "# print('input sample:', input_sample)\n",
    "# print('label sample:', label_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:58.012313100Z",
     "start_time": "2024-07-21T15:37:57.982590Z"
    }
   },
   "id": "8d2b0b4d1930876e",
   "execution_count": 400
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 19])\n"
     ]
    }
   ],
   "source": [
    "print(input_sample.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:58.013313200Z",
     "start_time": "2024-07-21T15:37:57.985037400Z"
    }
   },
   "id": "7ea83ed54f081155",
   "execution_count": 401
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "shuffle = True\n",
    "hidden_size = 5\n",
    "num_layers = 2\n",
    "\n",
    "# create dataloader\n",
    "train_dataloader = DataLoader(train_data_set, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n",
    "test_dataloader = DataLoader(test_data_set, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n",
    "# test loader\n",
    "# x, y = next(iter(train_dataloader))\n",
    "# \n",
    "# print('x', x, 'y', y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:58.039313400Z",
     "start_time": "2024-07-21T15:37:57.987663500Z"
    }
   },
   "id": "e992d7c8e1e29632",
   "execution_count": 402
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# LTSM\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__() #super makes all the methods available in nn.Module available for the new class Net\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        self.soft_max = nn.Softmax(dim=1) # we want a binary output, not %\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "        c0 = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:58.040313Z",
     "start_time": "2024-07-21T15:37:58.001742600Z"
    }
   },
   "id": "d6d6aae47a1a113e",
   "execution_count": 403
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.027163982391357\n",
      "Epoch 2, Loss: 6.624287128448486\n",
      "Epoch 3, Loss: 6.347145080566406\n",
      "Epoch 4, Loss: 6.196864128112793\n",
      "Epoch 5, Loss: 7.25331449508667\n",
      "Epoch 6, Loss: 6.129487991333008\n",
      "Epoch 7, Loss: 6.517644882202148\n",
      "Epoch 8, Loss: 6.73011589050293\n",
      "Epoch 9, Loss: 7.253875732421875\n",
      "Epoch 10, Loss: 7.013100624084473\n",
      "Epoch 11, Loss: 6.2647247314453125\n",
      "Epoch 12, Loss: 7.514076232910156\n",
      "Epoch 13, Loss: 7.620029449462891\n",
      "Epoch 14, Loss: 7.017556190490723\n",
      "Epoch 15, Loss: 5.976147651672363\n",
      "Epoch 16, Loss: 7.243841171264648\n",
      "Epoch 17, Loss: 5.879569053649902\n",
      "Epoch 18, Loss: 6.194151878356934\n",
      "Epoch 19, Loss: 7.025102138519287\n",
      "Epoch 20, Loss: 7.543340682983398\n",
      "Epoch 21, Loss: 6.554609298706055\n",
      "Epoch 22, Loss: 6.763648986816406\n",
      "Epoch 23, Loss: 6.485945701599121\n",
      "Epoch 24, Loss: 6.905091285705566\n",
      "Epoch 25, Loss: 6.5032429695129395\n",
      "Epoch 26, Loss: 6.777698516845703\n",
      "Epoch 27, Loss: 6.230930805206299\n",
      "Epoch 28, Loss: 6.993796348571777\n",
      "Epoch 29, Loss: 6.493200302124023\n",
      "Epoch 30, Loss: 6.584588050842285\n",
      "Epoch 31, Loss: 6.459049701690674\n",
      "Epoch 32, Loss: 7.496618747711182\n",
      "Epoch 33, Loss: 7.155097961425781\n",
      "Epoch 34, Loss: 6.79941463470459\n",
      "Epoch 35, Loss: 6.446661949157715\n",
      "Epoch 36, Loss: 7.000314712524414\n",
      "Epoch 37, Loss: 6.5591959953308105\n",
      "Epoch 38, Loss: 7.6371002197265625\n",
      "Epoch 39, Loss: 7.060507774353027\n",
      "Epoch 40, Loss: 5.861185073852539\n",
      "Epoch 41, Loss: 7.919915676116943\n",
      "Epoch 42, Loss: 6.571681499481201\n",
      "Epoch 43, Loss: 6.445672512054443\n",
      "Epoch 44, Loss: 7.803596019744873\n",
      "Epoch 45, Loss: 7.321013927459717\n",
      "Epoch 46, Loss: 7.3486127853393555\n",
      "Epoch 47, Loss: 6.995725154876709\n",
      "Epoch 48, Loss: 6.446160316467285\n",
      "Epoch 49, Loss: 6.9932098388671875\n",
      "Epoch 50, Loss: 6.546623706817627\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "num_features = len(df_target_train_v2.columns) # this right now is just the close date. \n",
    "\n",
    "net = Net(input_size=num_features)\n",
    "criterion = nn.BCELoss(reduction='sum') # for binary prediction. Using the 'target' column\n",
    "#criterion = nn.MSELoss() # for regression, predicting the 'close' column\n",
    "optimizer = optim.Adam(\n",
    "    net.parameters(), lr=learning_rate\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for seqs, labels in train_dataloader:\n",
    "        seqs = seqs.view(batch_size, sequence_len, num_features)\n",
    "        outputs = net(seqs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    # early break if loss isn't changing beyond the learning rate\n",
    "    if loss.item() < .1:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:47:15.333131600Z",
     "start_time": "2024-07-21T15:37:58.005313400Z"
    }
   },
   "id": "2790534f5428cde2",
   "execution_count": 404
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Define MSE metric\n",
    "# mse = torchmetrics.regression.MeanSquaredError()\n",
    "# \n",
    "# net.eval()\n",
    "# with torch.no_grad():\n",
    "#     for seqs, labels in test_dataloader:\n",
    "#         seqs = seqs.view(batch_size, torch_X_test.shape[1], num_features)\n",
    "#         # Pass seqs to net and squeeze the result\n",
    "#         outputs = net(seqs).squeeze()\n",
    "#         mse(outputs, labels)\n",
    "# \n",
    "# # Compute final metric value\n",
    "# test_mse = mse.compute()\n",
    "# print(f\"Test MSE: {test_mse}\")\n",
    "# print(f\"Test RMSE: {test_mse**.5}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:47:15.333131600Z",
     "start_time": "2024-07-21T15:47:15.324419900Z"
    }
   },
   "id": "ae6937e7eff7177e",
   "execution_count": 405
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score: 0.0\n",
      "Test accuracy score: 0.5077507495880127\n"
     ]
    }
   ],
   "source": [
    "# # used for binary classifcation\n",
    "# f1 = torchmetrics.F1Score(num_classes=2, task='BINARY')\n",
    "# \n",
    "# net.eval()\n",
    "# with torch.no_grad():\n",
    "#     for seqs, labels in test_dataloader:\n",
    "#         seqs = seqs.view(batch_size, sequence_len, num_features)\n",
    "#         outputs = net(seqs).squeeze()\n",
    "#         f1(outputs, labels)\n",
    "# \n",
    "# print(f\"Test F1 score: {f1.compute()}\")\n",
    "\n",
    "acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for seqs, labels in test_dataloader:\n",
    "        seqs = seqs.view(batch_size, sequence_len, num_features)\n",
    "        outputs = net(seqs).squeeze()\n",
    "        acc(outputs, labels)\n",
    "\n",
    "print(f\"Test accuracy score: {acc.compute()}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:49:37.140786700Z",
     "start_time": "2024-07-21T15:49:26.070247200Z"
    }
   },
   "id": "a9824920abf3b48d",
   "execution_count": 410
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results\n",
    "\n",
    "Baseline guessing "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bd50b5d6e213ee0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.4687579112426077"
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_guess_likelihood = df.target.mean()\n",
    "\n",
    "random_guess_likelihood"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:53:44.019541300Z",
     "start_time": "2024-07-21T15:53:44.016169800Z"
    }
   },
   "id": "acdd08bdbd74c444",
   "execution_count": 413
  },
  {
   "cell_type": "markdown",
   "source": [
    "At the minute level, 46.875% of the time the next close price is higher than the previous close price for VOO. \n",
    "The model is able to correctly predict a candle 50.077% of the time making it not much better than a random (weighted) coinflip. The thing holding the model back is that it doesn't take into account expected payoff. The average positive candel is higher than the average negative candle in absolute terms. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3db37e546b6057c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
